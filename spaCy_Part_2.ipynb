{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2XC5yV+LaHqqWTImZuZmw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKZBqCKpGGxF",
        "outputId": "9ee7f864-304e-4d9f-e207-2f1c98941c33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5439657043933447811\n",
            "cat\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "doc = nlp(\"I have a cat\")\n",
        "\n",
        "# Look up the hash for the word \"cat\"\n",
        "cat_hash = nlp.vocab.strings[\"cat\"]\n",
        "print(cat_hash)\n",
        "\n",
        "# Look up the cat_hash to get the string\n",
        "cat_string = nlp.vocab.strings[cat_hash]\n",
        "print(cat_string)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "doc = nlp(\"David Bowie is a PERSON\")\n",
        "\n",
        "# Look up the hash for the string label \"PERSON\"\n",
        "person_hash = nlp.vocab.strings[\"PERSON\"]\n",
        "print(person_hash)\n",
        "\n",
        "# Look up the person_hash to get the string\n",
        "person_string = nlp.vocab.strings[person_hash]\n",
        "print(person_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yQ198vIGWJI",
        "outputId": "9bcca771-801e-43f6-c438-69044131c743"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "380\n",
            "PERSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "\n",
        "from spacy.tokens import Doc\n",
        "\n",
        "\n",
        "words = [\"Go\", \",\", \"get\", \"started\", \"!\"]\n",
        "spaces = [False, True, True, False, False]\n",
        "\n",
        "# Create a Doc from the words and spaces\n",
        "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
        "print(doc.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwE37JTiJK9V",
        "outputId": "462fcc66-5b11-495a-8d9a-553189bf33fa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go, get started!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the Doc and Span objects manually, and update the named entities\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "\n",
        "from spacy.tokens import Doc, Span\n",
        "\n",
        "words = [\"I\", \"like\", \"David\", \"Bowie\"]\n",
        "spaces = [True, True, True, False]\n",
        "\n",
        "\n",
        "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
        "print(doc.text)\n",
        "\n",
        "\n",
        "span = Span(doc, 2, 4, label=\"PERSON\")\n",
        "print(span.text, span.label_)\n",
        "\n",
        "\n",
        "doc.ents = [span]\n",
        "\n",
        "\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVk7FD0cJLNn",
        "outputId": "d4a774fe-67c5-4fdf-b513-db08f4f46384"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I like David Bowie\n",
            "David Bowie PERSON\n",
            "[('David Bowie', 'PERSON')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Berlin looks like a nice city\")\n",
        "\n",
        "\n",
        "for token in doc:\n",
        "    # Check if the current token is a proper noun\n",
        "    if token.pos_ == \"PROPN\":\n",
        "        # Check if the next token is a verb\n",
        "        if doc[token.i + 1].pos_ == \"VERB\":\n",
        "            print(\"Found proper noun before a verb:\", token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5B4yWBSJ9Dv",
        "outputId": "a7917ecb-e570-437c-a3f7-2f4f55f6e65c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found proper noun before a verb: Berlin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zpvAeBsNR1N",
        "outputId": "c530cbf7-573a-42dd-bab5-c13c859de972"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 07:09:45.811922: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-11 07:09:45.811983: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-11 07:09:45.812017: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-11 07:09:47.093042: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-md==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.6.0/en_core_web_md-3.6.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Similarity:\n",
        "# Load a larger pipeline with vectors\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "doc1 = nlp(\"I like fast food\")\n",
        "doc2 = nlp(\"I like pizza\")\n",
        "print(doc1.similarity(doc2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WYuKWhrN0eD",
        "outputId": "9d4b4744-f723-447c-88f2-01514b9074f0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8698332283318978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = nlp(\"It's a warm summer day\")\n",
        "doc2 = nlp(\"It's sunny outside\")\n",
        "\n",
        "\n",
        "similarity = doc1.similarity(doc2)\n",
        "print(similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wnCMB23O3MB",
        "outputId": "fb550777-acd9-4874-ab2d-d78aaaf3ee36"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8220092482601077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"I like pizza and burger\") #Comparing two tokens\n",
        "token1 = doc[2]\n",
        "token2 = doc[4]\n",
        "print(token1.similarity(token2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vM6d138GODwR",
        "outputId": "ea028518-0cee-4bcb-d951-fcbc6133cfdb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7529191970825195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"TV and books\")\n",
        "token1, token2 = doc[0], doc[2]\n",
        "\n",
        "# Get the similarity of the tokens \"TV\" and \"books\"\n",
        "similarity = token1.similarity(token2)\n",
        "print(similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsSUJSeUPCDp",
        "outputId": "8896e4b5-d13d-4884-e9bc-1f477f3c4887"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10219937562942505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"This was a great restaurant. Afterwards, we went to a really nice bar.\")\n",
        "\n",
        "# Create spans for \"great restaurant\" and \"really nice bar\"\n",
        "span1 = doc[3:5]\n",
        "span2 = doc[12:15]\n",
        "\n",
        "# Get the similarity of the spans\n",
        "similarity = span1.similarity(span2)\n",
        "print(similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1vsHoJvPRAc",
        "outputId": "6458d225-2f52-4a29-a7cb-66bf2de2b596"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6348510384559631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "\n",
        "doc = nlp(\"Two bananas in pyjamas\")\n",
        "\n",
        "# Get the vector for the token \"bananas\"\n",
        "bananas_vector = doc[1].vector\n",
        "print(bananas_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6i8CJR1OTk4",
        "outputId": "8b93951e-2771-463e-d4b2-8d0cf933ffde"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-2.1689e-01 -2.5989e+00 -1.3144e+00  2.2500e+00 -4.6767e-01 -2.0695e+00\n",
            " -6.3379e-01 -4.0222e-01 -3.4022e+00 -3.6932e-01 -7.9938e-01 -1.0412e+00\n",
            "  9.3756e-01  1.6070e+00  8.8330e-01 -2.8483e+00  1.3349e-01 -3.1656e+00\n",
            "  8.1896e-01 -4.8113e+00  1.5655e+00  1.6665e+00 -4.7081e-01 -1.9475e+00\n",
            " -1.1779e+00 -1.3810e+00 -2.0071e+00 -2.1639e-01  9.0609e-01  1.5279e+00\n",
            "  1.2587e-04 -2.9000e+00  7.6069e-01 -2.2825e+00  1.2495e-02 -1.5653e+00\n",
            "  2.0052e+00 -1.7747e+00  5.9220e-01 -1.1428e+00 -1.3441e+00  3.4784e-01\n",
            "  1.7492e+00  1.9086e+00  1.0600e+00  1.2965e+00  4.1431e-01  7.9416e-01\n",
            " -1.1277e+00 -1.1403e+00  7.5891e-01 -9.4419e-01  1.4413e+00 -2.2554e+00\n",
            "  1.6226e-01  3.8901e-01  1.2299e-01  1.1577e+00  1.5524e+00  1.3853e+00\n",
            "  1.1112e+00  7.5767e-01  3.9431e+00 -2.8506e-01 -2.1645e+00 -1.0862e+00\n",
            " -1.4973e+00 -1.2781e+00  2.4643e+00 -1.5886e+00  2.5679e-01  6.4918e-01\n",
            "  1.6809e-01  5.7693e-01  3.1121e-01 -4.5278e-01 -2.7555e+00 -2.1846e+00\n",
            "  4.4865e+00  2.7107e-01 -5.3831e-01  8.3013e-01  6.7752e-02  1.4234e-01\n",
            "  1.2585e+00 -8.5423e-01  9.2971e-01 -3.9940e-01 -5.8663e-01  6.6604e-01\n",
            "  2.3871e+00  4.9333e-01  2.3922e+00 -3.7396e+00 -3.9524e-01 -6.3799e-01\n",
            "  3.3500e+00 -2.0430e+00 -1.5601e+00 -2.3594e+00 -1.4671e+00 -3.2848e+00\n",
            "  1.5197e+00 -1.1674e+00 -1.2885e+00  3.4890e+00 -4.0526e+00  1.6946e+00\n",
            " -1.5310e+00  2.6790e+00  1.2865e+00 -2.9286e-02  3.1037e+00  1.3635e-01\n",
            " -1.3327e-01  5.4603e-01  1.2937e+00 -2.3662e+00  2.8862e-01  1.6226e+00\n",
            "  6.3531e-01  1.5498e+00 -2.3349e+00  1.6150e+00 -2.0071e+00 -4.8784e-01\n",
            "  1.7768e+00 -2.6920e+00  1.6341e+00  4.0537e-01  3.7324e-01  7.8494e-01\n",
            "  1.3917e+00 -2.9035e-01  2.5224e+00  1.2485e+00 -1.5159e+00 -2.0832e+00\n",
            " -1.8766e-01 -1.3394e+00 -5.3597e-01 -2.4915e+00  1.6341e+00 -3.0336e+00\n",
            "  1.8791e-01 -2.4776e-01  1.6347e+00 -7.0009e-01  2.1221e+00 -2.3470e+00\n",
            " -2.1513e+00  1.2630e+00 -2.8195e-01 -5.6535e-01 -9.0373e-01  1.3455e+00\n",
            "  4.1099e+00  6.9325e-01  4.6835e-01  2.9949e-01 -3.2456e-01 -2.1713e+00\n",
            "  4.6691e-01 -1.3795e-01  6.0910e-01 -1.3374e+00 -8.3586e-01  1.8260e+00\n",
            " -4.5386e-01  1.2555e+00 -6.6705e-01 -3.0835e-01 -1.4692e-01  3.9952e+00\n",
            " -1.1289e+00  1.7926e-01 -5.8095e-01  6.2500e-01  2.6151e+00 -1.3212e+00\n",
            " -1.9355e+00  2.4898e+00 -1.7301e+00  8.6154e-01 -2.5272e+00 -3.0166e+00\n",
            "  5.8867e-01 -1.4207e-01  1.7611e+00 -1.0399e+00  5.7063e-01  7.2554e-01\n",
            "  8.7684e-01  1.6996e+00  1.1084e+00 -2.6877e-01 -2.2970e+00  1.8850e+00\n",
            "  1.2536e-01  1.1671e+00 -1.3038e+00  8.2640e-01  3.8002e-01 -1.0354e+00\n",
            "  2.2547e+00 -2.4526e-01  8.3622e-01 -7.9525e-01  1.4251e+00  4.5795e-02\n",
            "  2.5062e+00  7.2175e-01 -3.8197e-01  1.1387e+00  1.6779e+00 -1.6925e+00\n",
            "  8.2290e-02 -3.3117e-01 -6.1974e-01  8.0306e-01  2.1189e+00 -7.8231e-01\n",
            "  3.3266e-01 -7.1646e-01  1.7721e+00 -1.2573e+00  1.5601e-01  9.6129e-01\n",
            "  4.8986e-01  3.1657e+00 -3.0332e+00 -9.1339e-01 -2.8627e-01 -9.8174e-01\n",
            " -2.7599e+00  2.9160e+00 -1.1540e+00  2.9537e+00 -1.1502e+00 -2.2760e+00\n",
            "  1.1679e+00  2.0314e-01 -2.2882e+00  1.0485e+00 -4.9545e-01  2.4065e+00\n",
            "  9.1433e-01  1.3808e-01 -1.1361e+00 -1.2278e+00 -1.8958e+00 -2.4934e-01\n",
            " -4.1792e+00 -1.3781e+00 -8.9829e-01 -1.4802e+00 -1.2894e+00  2.2336e+00\n",
            " -2.4411e+00  3.0410e-01  2.1452e+00  1.8540e+00 -3.3640e-01  4.2768e-01\n",
            " -4.2577e-01  2.2337e-01  3.3650e+00 -2.1996e-01 -1.7426e+00  1.4554e+00\n",
            "  2.5087e+00 -1.1257e+00  1.4096e+00  1.3704e-01  7.6963e-01 -7.6688e-02\n",
            " -6.1875e-01 -2.0445e-01  4.9965e-01 -6.7246e-01 -4.0058e-01 -1.1536e+00\n",
            " -9.2837e-01 -2.5444e+00 -1.9880e-01 -2.1432e+00 -1.8218e+00 -5.7831e-01\n",
            " -1.6785e+00  2.6610e+00  1.0343e+00 -1.4297e+00  1.4563e+00 -2.0388e+00\n",
            " -1.4377e+00 -9.7985e-01  2.9488e+00 -2.7107e-01 -2.4010e-01 -1.3845e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\n",
        "    \"Twitch Prime, the perks program for Amazon Prime members offering free \"\n",
        "    \"loot, games and other benefits, is ditching one of its best features: \"\n",
        "    \"ad-free viewing. According to an email sent out to Amazon Prime members \"\n",
        "    \"today, ad-free viewing will no longer be included as a part of Twitch \"\n",
        "    \"Prime for new members, beginning on September 14. However, members with \"\n",
        "    \"existing annual subscriptions will be able to continue to enjoy ad-free \"\n",
        "    \"viewing until their subscription comes up for renewal. Those with \"\n",
        "    \"monthly subscriptions will have access to ad-free viewing until October 15.\"\n",
        ")\n",
        "\n",
        "\n",
        "pattern1 = [{\"LOWER\": \"amazon\"}, {\"IS_TITLE\": True, \"POS\": \"PROPN\"}]\n",
        "pattern2 = [{\"LOWER\": \"ad\"}, {\"TEXT\": \"-\"}, {\"LOWER\": \"free\"}, {\"POS\": \"NOUN\"}]\n",
        "\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "matcher.add(\"PATTERN1\", [pattern1])\n",
        "matcher.add(\"PATTERN2\", [pattern2])\n",
        "\n",
        "\n",
        "for match_id, start, end in matcher(doc):\n",
        "\n",
        "    print(doc.vocab.strings[match_id], doc[start:end].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TE57clYOD2h",
        "outputId": "4c37c8b5-5164-4e60-84e8-03ccc18ad8c8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PATTERN1 Amazon Prime\n",
            "PATTERN2 ad-free viewing\n",
            "PATTERN1 Amazon Prime\n",
            "PATTERN2 ad-free viewing\n",
            "PATTERN2 ad-free viewing\n",
            "PATTERN2 ad-free viewing\n"
          ]
        }
      ]
    }
  ]
}